{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 04. Color Object Detection \n",
    "\n",
    "Now we have a more complex scenario. We have several objects of the same colour, i.e. 5 yellow balls. They are diposed around the scene having diferent sizes. What we want now is to track the only one that is moving around, no matter its size. \n",
    "\n",
    "\n",
    "### Goals:\n",
    "* Step 1: Basic motion detection \n",
    "\n",
    "* Step 2: Detect the presence of colored objects using computer vision techniques.\n",
    "\n",
    "* Step 3: Track the object as it moves around in the video frames, drawing its previous positions as it moves, creating a tail behind it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "\n",
    "#Convenience resize function\n",
    "def resize(image, width=None, height=None, inter=cv2.INTER_AREA):\n",
    "    # initialize the dimensions of the image to be resized and\n",
    "    # grab the image size\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    # if both the width and height are None, then return the\n",
    "    # original image\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "\n",
    "    # check to see if the width is None\n",
    "    if width is None:\n",
    "        # calculate the ratio of the height and construct the\n",
    "        # dimensions\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "\n",
    "    # otherwise, the height is None\n",
    "    else:\n",
    "        # calculate the ratio of the width and construct the\n",
    "        # dimensions\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    # resize the image\n",
    "    resized = cv2.resize(image, dim, interpolation=inter)\n",
    "\n",
    "    # return the resized image\n",
    "    return resized\n",
    "VIDEODEV = 0\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Get the color feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower = (0,108,121)\n",
      "Upper = (72,255,255)\n"
     ]
    }
   ],
   "source": [
    "def setup_trackbars(range_filter):\n",
    "    cv2.namedWindow(\"Trackbars\", 0)\n",
    "    for i in [\"MIN\", \"MAX\"]:\n",
    "        for j in range_filter:\n",
    "            v = 0 if i == \"MIN\" else 255\n",
    "            cv2.createTrackbar(\"%s_%s\" % (j, i), \"Trackbars\", v, 255, lambda x : None)\n",
    "            \n",
    "            \n",
    "\n",
    "def get_trackbar_values(range_filter):\n",
    "    values = {}\n",
    "\n",
    "    for i in [\"MIN\", \"MAX\"]:\n",
    "        for j in range_filter:\n",
    "            v = cv2.getTrackbarPos(\"%s_%s\" % (j, i), \"Trackbars\")\n",
    "            values[\"%s_%s\" % (j, i)] = v\n",
    "    return values\n",
    "\n",
    "camera = cv2.VideoCapture(VIDEODEV); assert camera.isOpened()\n",
    "setup_trackbars('HSV')\n",
    "while True:\n",
    "        (grabbed, frame) = camera.read()\n",
    "        frame_to_thresh = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        v = get_trackbar_values('HSV')\n",
    "        thresh = cv2.inRange(frame_to_thresh, (v['H_MIN'], v['S_MIN'], v['V_MIN']), (v['H_MAX'], v['S_MAX'], v['V_MAX']))\n",
    "        cv2.imshow(\"Original\", frame)\n",
    "        cv2.imshow(\"Thresh\", thresh)\n",
    "        if cv2.waitKey(1) & 0xFF is ord('q'):\n",
    "            break\n",
    "            \n",
    "print \"Lower = (%d,%d,%d)\" % (v['H_MIN'], v['S_MIN'], v['V_MIN'])\n",
    "print \"Upper = (%d,%d,%d)\" % (v['H_MAX'], v['S_MAX'], v['V_MAX'])\n",
    "# cleanup the camera and close any open windows\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the lower and upper boundaries of the \"yellow\"\n",
    "# ball in the HSV color space, then initialize the\n",
    "# list of tracked points\n",
    "colorLower = (v['H_MIN'], v['S_MIN'], v['V_MIN'])\n",
    "colorUpper = (v['H_MAX'], v['S_MAX'], v['V_MAX'])\n",
    "tailsize = 64\n",
    "pts = deque(maxlen=tailsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define the color range of our object in the HSV color space. For this we will use a set of trackbars H_Min, H_Max, S_Min, S_Max, V_Min, V_Max for trying to isolate our object. To do that we will use the inRange function which return a binary image with true values where the pixels in the original frame falls between the given range in [HSV](https://en.wikipedia.org/wiki/HSL_and_HSV) color space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "camera = cv2.VideoCapture(VIDEODEV); assert camera.isOpened()\n",
    "# keep looping\n",
    "while True:\n",
    "    # grab the current frame\n",
    "    (grabbed, frame) = camera.read()\n",
    "    \n",
    "    # resize the frame, blur it, and convert it to the HSV\n",
    "    # color space\n",
    "    frame = resize(frame, width=600)\n",
    "    blurred = cv2.GaussianBlur(frame, (11, 11), 0)\n",
    "    hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)\n",
    "     # show the frame to our screen\n",
    "    cv2.imshow(\"HSV\", hsv)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    # if the 'q' key is pressed, stop the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "# cleanup the camera and close any open windows\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the reference frame for motion detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VIDEODEV = 0\n",
    "camera = cv2.VideoCapture(VIDEODEV); assert camera.isOpened()\n",
    "time.sleep(0.25)\n",
    "firstFrame = None\n",
    "\n",
    "# loop over the frames of the video\n",
    "while True:\n",
    "    # grab the current frame and initialize the occupied/unoccupied\n",
    "    # text\n",
    "    (grabbed, frame) = camera.read()\n",
    "    text = \"Unoccupied\"\n",
    " \n",
    "    # resize the frame, convert it to grayscale, and blur it\n",
    "    frame = resize(frame, width=500)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "    # draw the text and timestamp on the frame\n",
    "    cv2.putText(frame, \"Room Status: {}\".format(text), (10, 20),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "    cv2.putText(frame, datetime.datetime.now().strftime(\"%A %d %B %Y %I:%M:%S%p\"),(10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 255), 1)\n",
    " \n",
    "    # show the frame and record if the user presses a key\n",
    "    cv2.imshow(\"Security Feed\", gray)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    # if the `q` key is pressed, break from the lop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "    \n",
    "firstFrame = gray\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show the color feature detected and the movement if detected inside the circle area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "camera = cv2.VideoCapture(VIDEODEV); assert camera.isOpened()\n",
    "min_area = 500\n",
    "diffDelta = 25\n",
    "time.sleep(0.25)\n",
    "#colorLower = (0,157,109)\n",
    "#colorUpper = (255,255,255)\n",
    "# keep looping\n",
    "while True:\n",
    "    # grab the current frame\n",
    "    (grabbed, frame_orig) = camera.read()\n",
    "    \n",
    "    # resize the frame, blur it, and convert it to the HSV\n",
    "    # color space\n",
    "    frame = resize(frame_orig, width=600)\n",
    "    blurred = cv2.GaussianBlur(frame, (11, 11), 0)\n",
    "    hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    frame_grey = resize(frame_orig, width=500)\n",
    "    gray = cv2.cvtColor(frame_grey, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "    \n",
    "    # construct a mask for the color selected, then perform\n",
    "    # a series of dilations and erosions to remove any small\n",
    "    # blobs left in the mask\n",
    "    mask = cv2.inRange(hsv, colorLower, colorUpper)\n",
    "    mask = cv2.erode(mask, None, iterations=2)\n",
    "    mask = cv2.dilate(mask, None, iterations=2)\n",
    "    \n",
    "    \n",
    "    # compute the absolute difference between the current frame and\n",
    "    # first frame\n",
    "    frameDelta = cv2.absdiff(firstFrame, gray)\n",
    "    thresh = cv2.threshold(frameDelta, diffDelta, 255, cv2.THRESH_BINARY)[1]\n",
    " \n",
    "    # dilate the thresholded image to fill in holes, then find contours\n",
    "    # on thresholded image\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "    cnts_grey = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    " \n",
    "    # loop over the contours\n",
    "        #text = \"Occupied\"\n",
    "\n",
    "\n",
    "    # find contours in the mask and initialize the current\n",
    "    # (x, y) center of the ball\n",
    "    cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "    center = None\n",
    "\n",
    "    # only proceed if at least one contour was found\n",
    "    if len(cnts) > 0:\n",
    "        # find the largest contour in the mask, then use\n",
    "        # it to compute the minimum enclosing circle and\n",
    "        # centroid\n",
    "        c = max(cnts, key=cv2.contourArea)\n",
    "        ((x, y), radius) = cv2.minEnclosingCircle(c)\n",
    "        M = cv2.moments(c)\n",
    "        center = (int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]))\n",
    "        #if center[0]>x & center[0] < (x+w) & center[1]> y & center[1]\n",
    "        for cg in cnts_grey:\n",
    "        # if the contour is too small, ignore it\n",
    "            if cv2.contourArea(cg) < min_area:\n",
    "                continue\n",
    "        # compute the bounding box for the contour, draw it on the frame,\n",
    "        # and update the text\n",
    "            (x1, y1, w, h) = cv2.boundingRect(cg)\n",
    "            if x>x1 and x < (x1+w) and y>y1 and y<(y1+h):\n",
    "                cv2.rectangle(frame, (x1, y1), (x1 + w, y1 + h), (0, 255, 0), 2)\n",
    "        # only proceed if the radius meets a minimum size\n",
    "        if radius > 10:\n",
    "            # draw the circle and centroid on the frame,\n",
    "            # then update the list of tracked points\n",
    "            cv2.circle(frame, (int(x), int(y)), int(radius),(0, 255, 255), 2)\n",
    "            cv2.circle(frame, center, 5, (0, 0, 255), -1)\n",
    "            cv2.putText(frame, \"x: {}, y: {}\".format(center[0], center[1]),(10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.35, (0, 0, 255), 1)\n",
    "    # update the points queue\n",
    "    pts.appendleft(center)\n",
    "\n",
    "    # loop over the set of tracked points\n",
    "    for i in xrange(1, len(pts)):\n",
    "        # if either of the tracked points are None, ignore\n",
    "        # them\n",
    "        if pts[i - 1] is None or pts[i] is None:\n",
    "            continue\n",
    "\n",
    "        # otherwise, compute the thickness of the line and\n",
    "        # draw the connecting lines\n",
    "        thickness = int(np.sqrt(tailsize / float(i + 1)) * 2.5)\n",
    "        cv2.line(frame, pts[i - 1], pts[i], (0, 0, 255), thickness)\n",
    "\n",
    "         # show the frame and record if the user presses a key\n",
    "    cv2.imshow(\"Thresh\", thresh)\n",
    "    cv2.imshow(\"Frame Delta\", frameDelta)\n",
    "\n",
    "    # show the frame to our screen\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    # if the 'q' key is pressed, stop the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "# cleanup the camera and close any open windows\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
