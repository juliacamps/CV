{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 02. Track ball movement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals:\n",
    "* Step 1: Detect the presence of a colored ball using computer vision techniques.\n",
    "\n",
    "* Step 2: Track the ball as it moves around in the video frames, drawing its previous positions as it moves, creating a tail behind it\n",
    "\n",
    "* Step 3:  Determine the direction an object is moving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing the necessary packages and defining resize function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#Convenience resize function\n",
    "def resize(image, width=None, height=None, inter=cv2.INTER_AREA):\n",
    "    # initialize the dimensions of the image to be resized and\n",
    "    # grab the image size\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    # if both the width and height are None, then return the\n",
    "    # original image\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "\n",
    "    # check to see if the width is None\n",
    "    if width is None:\n",
    "        # calculate the ratio of the height and construct the\n",
    "        # dimensions\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "\n",
    "    # otherwise, the height is None\n",
    "    else:\n",
    "        # calculate the ratio of the width and construct the\n",
    "        # dimensions\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    # resize the image\n",
    "    resized = cv2.resize(image, dim, interpolation=inter)\n",
    "\n",
    "    # return the resized image\n",
    "    return resized\n",
    "CAMDEVICE = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start usb webcam and assure it works. The led on the webacam should blink "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Start Camera and check if it is open and releasse it \n",
    "camera = cv2.VideoCapture(CAMDEVICE); assert camera.isOpened()\n",
    "camera.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start from ball-tracking program previously explained.\n",
    "Additionally, we will define dx and dy, which tell us what is the differential in each coordinate in order to know in which direction is actually moving the object: \"Up\", \"Down\", \"Right\", \"Left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the lower and upper boundaries of the \"yellow\"\n",
    "# ball in the HSV color space, then initialize the\n",
    "# list of tracked points\n",
    "colorLower=(26,44,204)\n",
    "colorUpper=(32,255,255)\n",
    "tailsize = 64\n",
    "pts = deque(maxlen=tailsize)\n",
    "counter = 0\n",
    "(dX, dY) = (0, 0)\n",
    "direction = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s see how we can actually track the object movement, followed by using this object movement to compute the direction the object is moving using only (x, y)-coordinates of the object.\n",
    "We start to loop over the (x, y)-coordinates of object we are tracking. To infer the directional movement (if any), we compute dX and dY , the deltas (differences) between the x and y coordinates of the current frame and a frame towards the end of the buffer, respectively.\n",
    "\n",
    "However, it’s important to note that we don't compute the direction of the object between the current frame and the previous frame, because using the current frame and the previous frame is a bit of an unstable solution. Unless the object is moving very quickly, the deltas between the (x, y)-coordinates will be very small. If we were to use these deltas to report direction, then our results would be extremely noisy, implying that even small, minuscule changes in trajectory would be considered a direction change. In fact, these changes could be so small that they would be near invisible to the human eye. We are most likely not that interested reporting and tracking such small movements. Instead, it’s much more likely that we are interested in the larger object movements and reporting the direction in which the object is moving. Hence we compute the deltas between the coordinates of the current frame and a frame farther back in the queue. Performing this operation helps reduce noise and false reports of direction change.\n",
    "\n",
    "Next, we check the magnitude of the x-delta and y-delta to see if there is a significant difference in direction along any axis. In this case, if there is more than 20 pixel difference between the coordinates, we need to figure out in which direction the object is moving. If the sign of dX is positive, then we know the object is moving to the right. Otherwise, if the sign of dX is negative, then we are moving to the left. If the sign of dY is positive, then we’re moving up, otherwise the sign is negative and we’re moving down.\n",
    "\n",
    "However, it could be the case that both dX  and dY  have substantial directional movements (indicating diagonal movement), in such a case we have to update the direction variable accordingly.\n",
    "\n",
    "Note: You can make the direction detection code more sensitive by decreasing the threshold. In this case, a 20 pixel different obtains good results. However, if you want to detect tiny movements, simply decrease this value. On the other hand, if you want to only report large object movements, all you need to do is increase this threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "camera = cv2.VideoCapture(CAMDEVICE); assert camera.isOpened()\n",
    "threshold = 30\n",
    "previous_point = 10\n",
    "\n",
    "# keep looping\n",
    "while True:\n",
    "    # grab the current frame\n",
    "    (grabbed, frame) = camera.read()\n",
    "    \n",
    "    # resize the frame, blur it, and convert it to the HSV\n",
    "    # color space\n",
    "    frame = resize(frame, width=600)\n",
    "    blurred = cv2.GaussianBlur(frame, (11, 11), 0)\n",
    "    hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # construct a mask for the color \"green\", then perform\n",
    "    # a series of dilations and erosions to remove any small\n",
    "    # blobs left in the mask\n",
    "    mask = cv2.inRange(hsv, colorLower, colorUpper)\n",
    "    mask = cv2.erode(mask, None, iterations=2)\n",
    "    mask = cv2.dilate(mask, None, iterations=2)\n",
    "    \n",
    "    # find contours in the mask and initialize the current\n",
    "    # (x, y) center of the ball\n",
    "    cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "    center = None\n",
    "    # only proceed if at least one contour was found\n",
    "    if len(cnts) > 0:\n",
    "        # find the largest contour in the mask, then use\n",
    "        # it to compute the minimum enclosing circle and\n",
    "        # centroid\n",
    "        c = max(cnts, key=cv2.contourArea)\n",
    "        ((x, y), radius) = cv2.minEnclosingCircle(c)\n",
    "        M = cv2.moments(c)\n",
    "        center = (int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]))\n",
    "        # only proceed if the radius meets a minimum size\n",
    "        if radius > 10:\n",
    "            # draw the circle and centroid on the frame,\n",
    "            # then update the list of tracked points\n",
    "            cv2.circle(frame, (int(x), int(y)), int(radius),(0, 255, 255), 2)\n",
    "            cv2.circle(frame, center, 5, (0, 0, 255), -1)\n",
    "    # update the points queue\n",
    "    pts.appendleft(center)\n",
    "    counter=counter+1\n",
    "    # loop over the set of tracked points\n",
    "    for current_point in xrange(1, len(pts)):\n",
    "        # if either of the tracked points are None, ignore\n",
    "        # them\n",
    "        if pts[current_point - 1] is None or pts[current_point] is None:\n",
    "            continue\n",
    "        # check to see if enough points have been accumulated in\n",
    "        # the buffer\n",
    "        if counter >= previous_point and current_point == 1 and pts[-previous_point] is not None:\n",
    "            # compute the difference between the x and y\n",
    "            # coordinates and re-initialize the direction\n",
    "            # text variables\n",
    "            dX = pts[-previous_point][0] - pts[current_point][0]\n",
    "            dY = pts[-previous_point][1] - pts[current_point][1]\n",
    "            (dirX, dirY) = (\"\", \"\")\n",
    " \n",
    "            # ensure there is significant movement in the\n",
    "            # x-direction\n",
    "            if np.abs(dX) > threshold:\n",
    "                dirX = \"Right\" if np.sign(dX) == 1 else \"Left\"\n",
    " \n",
    "            # ensure there is significant movement in the\n",
    "            # y-direction\n",
    "            if np.abs(dY) > threshold:\n",
    "                dirY = \"Up\" if np.sign(dY) == 1 else \"Down\"\n",
    "\n",
    "            # handle when both directions are non-empty\n",
    "            if dirX != \"\" and dirY != \"\":\n",
    "                direction = \"{}-{}\".format(dirY, dirX)\n",
    "            # otherwise, only one direction is non-empty\n",
    "            else:\n",
    "                direction = dirX if dirX != \"\" else dirY\n",
    "        thickness = int(np.sqrt(tailsize / float(current_point + 1)) * 2.5)\n",
    "        cv2.line(frame, pts[current_point - 1], pts[current_point], (0, 0, 255), thickness)\n",
    "\n",
    "    cv2.putText(frame, direction, (10, 30), cv2.FONT_HERSHEY_SIMPLEX,0.65, (0, 0, 255), 3)\n",
    "    cv2.putText(frame, \"dx: {}, dy: {}\".format(dX, dY),\n",
    "        (10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX,0.35, (0, 0, 255), 1)\n",
    "    # show the frame to our screen\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    # if the 'q' key is pressed, stop the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "# cleanup the camera and close any open windows\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples, code and explanations extracted from Adrian Rosebrock webpage:  http://www.pyimagesearch.com/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
