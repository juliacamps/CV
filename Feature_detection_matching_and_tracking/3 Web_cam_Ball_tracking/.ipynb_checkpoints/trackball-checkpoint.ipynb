{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 01. Ball Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals:\n",
    "* Step 1: Detect the presence of a colored ball using computer vision techniques.\n",
    "\n",
    "* Step 2: Track the ball as it moves around in the video frames, drawing its previous positions as it moves, creating a tail behind it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing the necessary packages and defining resize function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#Convenience resize function\n",
    "def resize(image, width=None, height=None, inter=cv2.INTER_AREA):\n",
    "    # initialize the dimensions of the image to be resized and\n",
    "    # grab the image size\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    # if both the width and height are None, then return the\n",
    "    # original image\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "\n",
    "    # check to see if the width is None\n",
    "    if width is None:\n",
    "        # calculate the ratio of the height and construct the\n",
    "        # dimensions\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "\n",
    "    # otherwise, the height is None\n",
    "    else:\n",
    "        # calculate the ratio of the width and construct the\n",
    "        # dimensions\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    # resize the image\n",
    "    resized = cv2.resize(image, dim, interpolation=inter)\n",
    "\n",
    "    # return the resized image\n",
    "    return resized\n",
    "\n",
    "VIDEODEV = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start usb webcam and assure it works. The led on the webacam should blink "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Start Camera and check if it is open and releasse it \n",
    "camera = cv2.VideoCapture(VIDEODEV); assert camera.isOpened()\n",
    "camera.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin just reading frames and showing them up. This loop  will continue until we press the q  key, indicating that we want to terminate the script. Inside the loop we make a call to the read  method of our camera which returns a 2-tuple. The first entry in the tuple, grabbed  is a boolean indicating whether the frame  was successfully read or not. The frame  is the video frame itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# keep looping\n",
    "import time\n",
    "camera = cv2.VideoCapture(VIDEODEV); assert camera.isOpened()\n",
    "time.sleep(0.25)\n",
    "while True:\n",
    "    # grab the current frame\n",
    "    (grabbed, frame) = camera.read()\n",
    "     # show the frame to our screen\n",
    "    cv2.imshow(\"Frame\", frame)   \n",
    "    # if the 'q' key is pressed, stop the loop\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF is ord('q'):\n",
    "        break\n",
    "        \n",
    "# cleanup the camera and close any open windows\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define the color range of our object in the HSV color space. For this we will use a set of trackbars H_Min, H_Max, S_Min, S_Max, V_Min, V_Max for trying to isolate our object. To do that we will use the inRange function which return a binary image with true values where the pixels in the original frame falls between the given range in [HSV](https://en.wikipedia.org/wiki/HSL_and_HSV) color space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower = (26,44,204)\n",
      "Upper = (32,255,255)\n"
     ]
    }
   ],
   "source": [
    "def setup_trackbars(range_filter):\n",
    "    cv2.namedWindow(\"Trackbars\", 0)\n",
    "    for i in [\"MIN\", \"MAX\"]:\n",
    "        for j in range_filter:\n",
    "            v = 0 if i == \"MIN\" else 255\n",
    "            cv2.createTrackbar(\"%s_%s\" % (j, i), \"Trackbars\", v, 255, lambda x : None)\n",
    "            \n",
    "            \n",
    "\n",
    "def get_trackbar_values(range_filter):\n",
    "    values = {}\n",
    "\n",
    "    for i in [\"MIN\", \"MAX\"]:\n",
    "        for j in range_filter:\n",
    "            v = cv2.getTrackbarPos(\"%s_%s\" % (j, i), \"Trackbars\")\n",
    "            values[\"%s_%s\" % (j, i)] = v\n",
    "    return values\n",
    "\n",
    "camera = cv2.VideoCapture(VIDEODEV); assert camera.isOpened()\n",
    "setup_trackbars('HSV')\n",
    "while True:\n",
    "        (grabbed, frame) = camera.read()\n",
    "        frame_to_thresh = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        v = get_trackbar_values('HSV')\n",
    "        thresh = cv2.inRange(frame_to_thresh, (v['H_MIN'], v['S_MIN'], v['V_MIN']), (v['H_MAX'], v['S_MAX'], v['V_MAX']))\n",
    "        cv2.imshow(\"Original\", frame)\n",
    "        cv2.imshow(\"Thresh\", thresh)\n",
    "        if cv2.waitKey(1) & 0xFF is ord('q'):\n",
    "            break\n",
    "            \n",
    "print \"Lower = (%d,%d,%d)\" % (v['H_MIN'], v['S_MIN'], v['V_MIN'])\n",
    "print \"Upper = (%d,%d,%d)\" % (v['H_MAX'], v['S_MAX'], v['V_MAX'])\n",
    "# cleanup the camera and close any open windows\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define the color range of our object in the HSV color space using the values found above. These color boundaries will allow us to detect the colored ball in our video file. \n",
    "the size of the tail of the ball and previous points queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the lower and upper boundaries of the \"yellow\"\n",
    "# ball in the HSV color space, then initialize the\n",
    "# list of tracked points\n",
    "colorLower = (v['H_MIN'], v['S_MIN'], v['V_MIN'])\n",
    "colorUpper = (v['H_MAX'], v['S_MAX'], v['V_MAX'])\n",
    "tailsize = 64\n",
    "pts = deque(maxlen=tailsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start to preprocess the capturated frame a bit. First of all we resize it to a more suitable size of 600 pixels-width. Downsizing the frame  allows us to process the frame faster, leading to an increase in FPS (since we have less image data to process)\n",
    "Next we will apply a blur filter all arround the frame to reduce high frequency noise and allow us to focus on the structural objects inside the frame, such as the ball. Finally, weâ€™ll convert the frame to the HSV color space, the same as the color range of our object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "camera = cv2.VideoCapture(VIDEODEV); assert camera.isOpened()\n",
    "# keep looping\n",
    "while True:\n",
    "    # grab the current frame\n",
    "    (grabbed, frame) = camera.read()\n",
    "    \n",
    "    # resize the frame, blur it, and convert it to the HSV\n",
    "    # color space\n",
    "    frame = resize(frame, width=600)\n",
    "    blurred = cv2.GaussianBlur(frame, (11, 11), 0)\n",
    "    hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)\n",
    "     # show the frame to our screen\n",
    "    cv2.imshow(\"HSV\", hsv)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    # if the 'q' key is pressed, stop the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "# cleanup the camera and close any open windows\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the same ``inRange`` on the hsv frame using the range obtained before. The result is a binary mask. A series of erosions and dilations  remove any small blobs that my be left on the mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "camera = cv2.VideoCapture(VIDEODEV); assert camera.isOpened()\n",
    "# keep looping\n",
    "while True:\n",
    "    # grab the current frame\n",
    "    (grabbed, frame) = camera.read()\n",
    "    \n",
    "    # resize the frame, blur it, and convert it to the HSV\n",
    "    # color space\n",
    "    frame = resize(frame, width=600)\n",
    "    blurred = cv2.GaussianBlur(frame, (11, 11), 0)\n",
    "    hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # construct a mask for the color \"green\", then perform\n",
    "    # a series of dilations and erosions to remove any small\n",
    "    # blobs left in the mask\n",
    "    mask = cv2.inRange(hsv, colorLower, colorUpper)\n",
    "    mask = cv2.erode(mask, None, iterations=2)\n",
    "    mask = cv2.dilate(mask, None, iterations=2)\n",
    "\n",
    "    # show the frame to our screen\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"Mask\", mask)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    # if the 'q' key is pressed, stop the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "# cleanup the camera and close any open windows\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to find the contour (i.e. outline) of the ball and draw it on our frame. \n",
    "We start by computing the contours of the object(s) in the image usign ``cv2.findContours``. We specify an array slice of -2 to make the function compatible with both OpenCV 2.4 and OpenCV 3.\n",
    "If we found more than one contour, then we find the largest contour in the cnts list applyng max to contourArea of each contour. Then we compute the minimum enclosing circle of the blob, using ``minEnclosingCircle``, and then compute the center (x, y)-coordinates (i.e. the [centroids](https://en.wikipedia.org/wiki/Image_moment#Central_moments))  using the ``moments`` function on the contour.  This function calculates all of the moments up to the third order of a blob. Thus,  ``int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"])`` give us the coordinate of *the center of mass* of our blob.\n",
    "\n",
    "Then we make a quick check to ensure that the radius  of the minimum enclosing circle is sufficiently large. If the radius passes the test, we then draw two circles: one surrounding the ball itself and another to indicate the centroid of the ball. Additionaly the actual position of the moments and enclosingCircle is showed on the bottom of the screen. Notice how the moments are more stable thant the enclosingCircle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "camera = cv2.VideoCapture(VIDEODEV); assert camera.isOpened()\n",
    "# keep looping\n",
    "while True:\n",
    "    # grab the current frame\n",
    "    (grabbed, frame) = camera.read()\n",
    "    \n",
    "    # resize the frame, blur it, and convert it to the HSV\n",
    "    # color space\n",
    "    frame = resize(frame, width=600)\n",
    "    blurred = cv2.GaussianBlur(frame, (11, 11), 0)\n",
    "    hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # construct a mask for the color selected, then perform\n",
    "    # a series of dilations and erosions to remove any small\n",
    "    # blobs left in the mask\n",
    "    mask = cv2.inRange(hsv, colorLower, colorUpper)\n",
    "    mask = cv2.erode(mask, None, iterations=2)\n",
    "    mask = cv2.dilate(mask, None, iterations=2)\n",
    "    \n",
    "    # find contours in the mask and initialize the current\n",
    "    # (x, y) center of the ball\n",
    "    cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "    center = None\n",
    "\n",
    "    # only proceed if at least one contour was found\n",
    "    if len(cnts) > 0:\n",
    "        # find the largest contour in the mask, then use\n",
    "        # it to compute the minimum enclosing circle and\n",
    "        # centroid\n",
    "        cmax = max(cnts, key=cv2.contourArea)\n",
    "        ((x, y), radius) = cv2.minEnclosingCircle(cmax)\n",
    "        M = cv2.moments(cmax)\n",
    "        center = (int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]))\n",
    "        # only proceed if the radius meets a minimum size\n",
    "        if radius > 10:\n",
    "            # draw the minimum enclosing circle, yellow colour in BGR format(), thickness = 2\n",
    "            cv2.circle(frame, (int(x), int(y)), int(radius),(0, 255, 255), 2)\n",
    "            # draw the centroid,radius 5, red colour in BGR format(), thikness < 0 meaning that the circle is filled.\n",
    "            cv2.circle(frame, center, 5, (0, 0, 255), -1)\n",
    "            cv2.putText(frame, \"Centroid  x: {}, y: {}\".format(center[0], center[1]),(10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.35, (0, 0, 255), 1)\n",
    "            cv2.putText(frame, \"minEnclosing: x: {}, y: {}\".format(int(x), int(y)),(10, frame.shape[0] - 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.35, (0, 0, 255), 1)\n",
    "\n",
    "    # show the frame to our screen\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    # if the 'q' key is pressed, stop the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "# cleanup the camera and close any open windows\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, what we do is to draw the contrail of the ball, i.e. the past N (x, y)-coordinates the ball has been detected at. We start looping over each of the pts. If either the current point or the previous point is None  (indicating that the ball was not successfully detected in that given frame), then we ignore the current index continue looping over the pts. If both points are valid, we compute the thickness  of the contrail and then draw it on the frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "camera = cv2.VideoCapture(VIDEODEV); assert camera.isOpened()\n",
    "# keep looping\n",
    "while True:\n",
    "    # grab the current frame\n",
    "    (grabbed, frame) = camera.read()\n",
    "    \n",
    "    # resize the frame, blur it, and convert it to the HSV\n",
    "    # color space\n",
    "    frame = resize(frame, width=600)\n",
    "    blurred = cv2.GaussianBlur(frame, (11, 11), 0)\n",
    "    hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # construct a mask for the color selected, then perform\n",
    "    # a series of dilations and erosions to remove any small\n",
    "    # blobs left in the mask\n",
    "    mask = cv2.inRange(hsv, colorLower, colorUpper)\n",
    "    mask = cv2.erode(mask, None, iterations=2)\n",
    "    mask = cv2.dilate(mask, None, iterations=2)\n",
    "    \n",
    "    # find contours in the mask and initialize the current\n",
    "    # (x, y) center of the ball\n",
    "    cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "    center = None\n",
    "\n",
    "    # only proceed if at least one contour was found\n",
    "    if len(cnts) > 0:\n",
    "        # find the largest contour in the mask, then use\n",
    "        # it to compute the minimum enclosing circle and\n",
    "        # centroid\n",
    "        c = max(cnts, key=cv2.contourArea)\n",
    "        ((x, y), radius) = cv2.minEnclosingCircle(c)\n",
    "        M = cv2.moments(c)\n",
    "        center = (int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]))\n",
    "        \n",
    "        # only proceed if the radius meets a minimum size\n",
    "        if radius > 10:\n",
    "            # draw the circle and centroid on the frame,\n",
    "            # then update the list of tracked points\n",
    "            cv2.circle(frame, (int(x), int(y)), int(radius),(0, 255, 255), 2)\n",
    "            cv2.circle(frame, center, 5, (0, 0, 255), -1)\n",
    "            cv2.putText(frame, \"x: {}, y: {}\".format(center[0], center[1]),(10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.35, (0, 0, 255), 1)\n",
    "    # update the points queue\n",
    "    pts.appendleft(center)\n",
    "\n",
    "    # loop over the set of tracked points\n",
    "    for i in xrange(1, len(pts)):\n",
    "        # if either of the tracked points are None, ignore\n",
    "        # them\n",
    "        if pts[i - 1] is None or pts[i] is None:\n",
    "            continue\n",
    "\n",
    "        # otherwise, compute the thickness of the line and\n",
    "        # draw the connecting lines\n",
    "        thickness = int(np.sqrt(tailsize / float(i + 1)) * 2.5)\n",
    "        cv2.line(frame, pts[i - 1], pts[i], (0, 0, 255), thickness)\n",
    "\n",
    "    # show the frame to our screen\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    # if the 'q' key is pressed, stop the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "# cleanup the camera and close any open windows\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples, code and explanations extracted from Adrian Rosebrock webpage:  http://www.pyimagesearch.com/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
